import streamlit as st
import pandas as pd
import numpy as np
import datetime as dt
import plotly.express as px
from statsmodels.tsa.api import ExponentialSmoothing

# --- Page Configuration ---
st.set_page_config(
    page_title="Sales & Inventory Dashboard",
    page_icon="ðŸ“Š",
    layout="wide"
)

# --- Data Loading and Caching ---
@st.cache_data
def load_data():
    # Using a relative path is better for portability
    df_raw = pd.read_excel('data/Online Retail.xlsx')
    df = df_raw.dropna(subset=['CustomerID'])
    df = df.drop_duplicates()
    df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]
    df = df[df['Quantity'] > 0]
    df = df[df['UnitPrice'] > 0]
    df['CustomerID'] = df['CustomerID'].astype(int)
    df['StockCode'] = df['StockCode'].astype(str).str.strip()
    df['TotalPrice'] = df['Quantity'] * df['UnitPrice']
    return df

df = load_data()

# --- Main Dashboard Title ---
st.title("ðŸ“ˆ E-commerce Sales & Inventory Dashboard")

# --- Tabs ---
tab1, tab2, tab3, tab4, tab5 = st.tabs(["ðŸ“Š Main Dashboard", "ðŸ“¦ ABC Analysis", "ðŸ‘¥ RFM Segmentation", "ðŸ“ˆ Demand Forecasting" , "ðŸ“„ Project Summary"])

# --- Tab 1: Main Dashboard ---
with tab1:
    st.header("Key Performance Indicators")
    col1, col2, col3 = st.columns(3)
    total_revenue = df['TotalPrice'].sum()
    total_transactions = df['InvoiceNo'].nunique()
    total_customers = df['CustomerID'].nunique()
    col1.metric("Total Revenue", f"${total_revenue:,.2f}")
    col2.metric("Total Transactions", f"{total_transactions:,}")
    col3.metric("Total Customers", f"{total_customers:,}")

    st.markdown("---")
    st.header("Sales Over Time")
    sales_over_time = df.set_index('InvoiceDate')['TotalPrice'].resample('M').sum()
    fig_sales = px.line(sales_over_time, x=sales_over_time.index, y='TotalPrice', title='Monthly Sales Revenue')
    st.plotly_chart(fig_sales, use_container_width=True)
    st.info("Note: The sharp drop in revenue for December 2011 is expected, as the dataset only includes sales data up to December 9th of that month.")


# --- Tab 2: ABC Analysis ---
with tab2:
    st.header("ABC Analysis - Product Prioritization")
    @st.cache_data
    def perform_abc_analysis(input_df):
        product_revenue = input_df.groupby('StockCode')['TotalPrice'].sum().reset_index().sort_values(by='TotalPrice', ascending=False)
        product_revenue['CumulativeRevenue'] = product_revenue['TotalPrice'].cumsum()
        total_revenue_abc = product_revenue['TotalPrice'].sum()
        product_revenue['CumulativePercentage'] = (product_revenue['CumulativeRevenue'] / total_revenue_abc) * 100
        def assign_abc_category(percentage):
            if percentage <= 80: return 'A'
            elif 80 < percentage <= 95: return 'B'
            else: return 'C'
        product_revenue['Category'] = product_revenue['CumulativePercentage'].apply(assign_abc_category)
        return product_revenue

    abc_df = perform_abc_analysis(df)
    category_counts = abc_df['Category'].value_counts().reset_index()
    
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Product Category Distribution")
        fig_abc = px.pie(category_counts, names='Category', values='count', title='Product Distribution by ABC Category', hole=0.4)
        st.plotly_chart(fig_abc, use_container_width=True)
    with col2:
        st.subheader("Top 10 'A' Products")
        top_a_products = abc_df[(abc_df['Category'] == 'A') & (~abc_df['StockCode'].isin(['POST', 'M']))].head(10)
        st.dataframe(top_a_products)

# --- Tab 3: RFM Analysis ---
with tab3:
    st.header("RFM Analysis - Customer Segmentation")
    @st.cache_data
    def perform_rfm_analysis(input_df):
        snapshot_date = input_df['InvoiceDate'].max() + dt.timedelta(days=1)
        rfm = input_df.groupby('CustomerID').agg({
            'InvoiceDate': lambda date: (snapshot_date - date.max()).days,
            'InvoiceNo': 'nunique',
            'TotalPrice': 'sum'
        }).reset_index()
        rfm.rename(columns={'InvoiceDate': 'Recency', 'InvoiceNo': 'Frequency', 'TotalPrice': 'MonetaryValue'}, inplace=True)
        r_labels = range(4, 0, -1); f_labels = range(1, 5); m_labels = range(1, 5)
        rfm['R_Score'] = pd.qcut(rfm['Recency'], q=4, labels=r_labels, duplicates='drop')
        rfm['F_Score'] = pd.qcut(rfm['Frequency'].rank(method='first'), q=4, labels=f_labels)
        rfm['M_Score'] = pd.qcut(rfm['MonetaryValue'], q=4, labels=m_labels)
        rfm['RFM_Score'] = rfm[['R_Score', 'F_Score', 'M_Score']].sum(axis=1)
        return rfm

    rfm_df = perform_rfm_analysis(df)
    st.subheader("RFM Score Distribution")
    fig_rfm = px.histogram(rfm_df, x='RFM_Score', title='Distribution of Customer RFM Scores')
    st.plotly_chart(fig_rfm, use_container_width=True)

# --- Tab 4: Demand Forecasting ---
with tab4:
    st.header("Demand Forecasting for Top Product (StockCode 22423)")
    @st.cache_data
    def generate_forecast(input_df):
        PRODUCT_TO_FORECAST = '22423'
        product_sales = input_df[input_df['StockCode'] == PRODUCT_TO_FORECAST]
        ts_daily = product_sales.set_index('InvoiceDate')['Quantity'].resample('D').sum().fillna(0)
        
        model = ExponentialSmoothing(
            ts_daily, seasonal='add', seasonal_periods=7,
            trend='add', initialization_method="estimated"
        ).fit()
        
        forecast = model.forecast(30)
        
        plot_df = pd.DataFrame({'Historical': ts_daily, 'Forecast': forecast})
        return plot_df

    forecast_df = generate_forecast(df)
    st.subheader("30-Day Sales Forecast")
    fig_forecast = px.line(forecast_df, title='Historical Sales vs. 30-Day Forecast')
    st.plotly_chart(fig_forecast, use_container_width=True)
    st.write("The forecast is based on the validated Exponential Smoothing model with a Mean Absolute Error (MAE) of 20.68 units.")

# --- NEW AESTHETIC SUMMARY TAB ---
with tab5:
    st.header(" Project Summary & Key Insights")
    st.markdown("This project provides a comprehensive analysis of e-commerce sales data, identifying key business drivers and delivering a validated demand forecast.")
    
    st.markdown("---")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ðŸ“¦ Product Performance (ABC)")
        st.metric(label="Percentage of High-Value SKUs (Class A)", value="21.1%")
        st.progress(80)
        st.markdown("The analysis revealed that a minority of products drive the majority of revenue, following the Pareto Principle. The top **21.1%** of SKUs are responsible for **80%** of total sales.")
        with st.expander("See Recommendation"):
            st.write("""
            **Focus inventory management and marketing efforts on Class A products.** By optimizing stock levels and promotional activities for these high-value items, the business can significantly increase profitability and capital efficiency.
            """)

    with col2:
        st.subheader("ðŸ‘¥ Customer Value (RFM)")
        st.metric(label="Percentage of 'Best Customers'", value="11.3%")
        st.progress(50)
        st.markdown("Customer value is highly concentrated. The top **11.3%** of customers, identified as 'Best Customers' through RFM segmentation, contribute **49.8%** of the total revenue.")
        with st.expander("See Recommendation"):
            st.write("""
            **Develop targeted loyalty and retention programs for this vital customer segment.** Personalized communication and rewards can ensure their continued patronage, securing a substantial portion of the business's revenue stream.
            """)
    
    st.markdown("---")
    st.subheader("ðŸ“ˆ Forecasting Validation")
    st.markdown("A demand forecast was developed for a top-selling product and rigorously validated against baseline models to ensure its predictive power.")
    
    col1, col2, col3 = st.columns(3)
    col1.metric("Validated Model MAE (Exponential Smoothing)", value="20.68")
    col2.metric("Baseline MAE (Naive)", value="32.10")
    col3.metric("Baseline MAE (Mean)", value="24.48")
    
    with st.expander("See Recommendation"):
            st.write("""
            **Utilize this forecast and its quantified error (MAE) to calculate optimal safety stock levels.** This data-driven approach allows the business to balance the risk of stockouts with the cost of holding excess inventory, leading to a more efficient supply chain.
            """)

    st.markdown("---")
    st.header("Project Conclusion")
    st.success("This dashboard successfully demonstrates an end-to-end data science workflow, transforming raw transactional data into actionable business intelligence.")